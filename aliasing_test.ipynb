{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Equivariant Downsampling Example\n",
    "\n",
    "This notebook demonstrates usage of our novel subgroup downsampling layer with equivariant anti-aliasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsampling.layers.downsampling import SubgroupDownsample\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Layer Configuration\n",
    " \n",
    "Configure the group structure and downsampling parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiq/Desktop/group_graph_pooling/gsampling/layers/sampling.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"sampling_matrix\", torch.tensor(sampling_matrix).clone()\n",
      "/home/ashiq/Desktop/group_graph_pooling/gsampling/layers/sampling.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"up_sampling_matrix\", torch.tensor(up_sampling_matrix).clone()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing anti-aliasing layer\n",
      "Equi Constraint:  True Equi Correction:  True\n",
      "===Using Linear Optimization====\n",
      "Initial guess M: (288,)\n",
      "Linear Constraint Matrix: (144, 288)\n",
      "*** starting optimization ***\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -2210726690.67739\n",
      "            Iterations: 14\n",
      "            Function evaluations: 4047\n",
      "            Gradient evaluations: 14\n",
      "*** optimization done ***\n",
      "Optimal objective value: -2210726690.67739\n",
      " Final Loss Reconstruction : 1.0926533015113843e-06\n",
      " Final Equivarinace loss : 2.44948974278317\n"
     ]
    }
   ],
   "source": [
    "# Fundamental group parameters\n",
    "input_group = 'dihedral'          # Symmetry group type (dihedral/Cn/symmetric)\n",
    "sub_group = 'dihedral'            # Subgroup type to downsample to\n",
    "input_group_order = 12            # Order of rotation elements for dihedral group\n",
    "sub_sampling_factor = 2           # Factor to reduce group size by\n",
    "\n",
    "# Feature configuration\n",
    "number_of_features = 10           # Channel dimension (equivariant features)\n",
    "generator = 'r-s'                 # Cayley graph generator (r=rotation, s=reflection)\n",
    "\n",
    "# Hardware configuration\n",
    "device = 'cuda:0'                 # Device for computation\n",
    "dtype = torch.float32             # Data type precision\n",
    "\n",
    "d_layer = SubgroupDownsample(\n",
    "    group_type=\"dihedral\",         # Parent group type\n",
    "    order=12,                     # Order of dihedral group (following escnn library convention)\n",
    "    sub_group_type=\"dihedral\",    # Subgroup type to downsample to\n",
    "    subsampling_factor=2,         # Factor to reduce group by\n",
    "    num_features=10,              # Number of input feature channels\n",
    "    generator=\"r-s\",              # Generators for Cayley graph construction              # Computation device\n",
    "    dtype=torch.float32,          # Data type\n",
    "    apply_antialiasing=True,      # Enable equivariant anti-aliasing\n",
    "    anti_aliasing_kwargs={        # Anti-aliasing optimization params\n",
    "        \"iterations\": 100,        # Number of optimization steps\n",
    "        \"smoothness_loss_weight\": 0.1, # Smoothness strength in optimization\n",
    "    },\n",
    ")\n",
    "d_layer = d_layer.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 240, 32, 32])\n",
      "Output shape: torch.Size([1, 120, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# make fake input tensor of size (batch_size, number_of_features * group_size, height, width)\n",
    "batch_size = 1\n",
    "group_size = input_group_order * 2 # dihedral group has 2*order elements following convention of escnn\n",
    "input_tensor = torch.randn(\n",
    "    batch_size,\n",
    "    number_of_features * group_size,\n",
    "    32,\n",
    "    32,\n",
    "    device=device,\n",
    "    dtype=dtype,\n",
    ")\n",
    "\n",
    "out, canonicalization_element = d_layer(input_tensor)\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "print(\"Output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Parameter Explanations:\n",
    "\n",
    "- **group_type**: Type of symmetry group (dihedral = rotation + reflections)\n",
    "- **order**: For dihedral groups, specifies number of rotational symmetries (N rotations + N reflections)\n",
    "- **subsampling_factor**: Integer reduction factor for group size (must divide group order)\n",
    "- **generator**: Cayley graph construction:\n",
    "  - 'r-s' = rotation + reflection generators\n",
    "  - 'r' = rotation-only generation\n",
    "  - Custom generator tuples supported\n",
    "- **anti_aliasing_kwargs**: Controls optimization of equivariant low-pass filter\n",
    "\n",
    "## 3. Input Tensor Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 240, 32, 32])\n",
      "Interpretation:\n",
      "- 10 feature channels\n",
      "- 24 group elements (dihedral D_12)\n",
      "- 32x32 spatial resolution\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "group_size = input_group_order * 2  # Dihedral group size = 2*order (rotations + reflections)\n",
    "height = width = 32                # Spatial dimensions\n",
    "\n",
    "# Create random input tensor\n",
    "input_tensor = torch.randn(\n",
    "    batch_size,\n",
    "    number_of_features * group_size,  # Channels last convention: [features × group_size]\n",
    "    height,\n",
    "    width,\n",
    "    device=device,\n",
    "    dtype=dtype,\n",
    ")\n",
    "\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "print(\"Interpretation:\")\n",
    "print(f\"- {number_of_features} feature channels\")\n",
    "print(f\"- {group_size} group elements (dihedral D_{input_group_order})\")\n",
    "print(f\"- {height}x{width} spatial resolution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, canonicalization_element = d_layer(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Output Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output shape: torch.Size([1, 120, 32, 32])\n",
      "Interpretation:\n",
      "- Same 10 feature channels\n",
      "- Reduced group size: 12 elements\n",
      "- Maintained spatial resolution: 32x32\n",
      "\n",
      "Canonicalization Element: [(-1, -1)]\n",
      "Purpose: Contains subgroup coset information for feature alignment. By default, canonicalization is set of false, so this output is not used.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(\"Interpretation:\")\n",
    "print(f\"- Same {number_of_features} feature channels\")\n",
    "print(f\"- Reduced group size: {out.shape[1]//number_of_features} elements\")\n",
    "print(f\"- Maintained spatial resolution: {out.shape[-2]}x{out.shape[-1]}\")\n",
    "\n",
    "print(\"\\nCanonicalization Element:\", canonicalization_element)\n",
    "print(\"Purpose: Contains subgroup coset information for feature alignment. By default, canonicalization is set of false, so this output is not used.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critical Shape Transformation\n",
    "\n",
    "The layer performs **group dimension reduction** while preserving features:\n",
    "\n",
    "| Dimension    | Input Size (channels x Group) | Output Size (channels x Group) | Notes                     |\n",
    "|--------------|------------|-------------|---------------------------|\n",
    "| Batch        | 1          | 1           | Unchanged                 |\n",
    "| Features     | 10×24      | 10×12       | 2× group reduction (D12→D6)|\n",
    "| Spatial      | 32×32      | 32×32       | Spatial resolution maintained |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsampling.models.model_handler import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antialiasing True\n",
      "Initializing anti-aliasing layer\n",
      "Equi Constraint:  True Equi Correction:  True\n",
      "===Using Linear Optimization====\n",
      "Initial guess M: (288,)\n",
      "Linear Constraint Matrix: (144, 288)\n",
      "*** starting optimization ***\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -2766735471.4094844\n",
      "            Iterations: 11\n",
      "            Function evaluations: 3179\n",
      "            Gradient evaluations: 11\n",
      "*** optimization done ***\n",
      "Optimal objective value: -2766735471.4094844\n",
      " Final Loss Reconstruction : 1.2018166076012732e-06\n",
      " Final Equivarinace loss : 2.4494897427831672\n"
     ]
    }
   ],
   "source": [
    "# Configure hierarchical group-equivariant architecture\n",
    "model = get_model(\n",
    "    input_channel=3,  # RGB input channels\n",
    "    num_channels=[32, 64, 128],  # Feature channels per stage\n",
    "    num_layers=3,     # Number of processing stages\n",
    "    dwn_group_types=[\n",
    "        [\"dihedral\", \"dihedral\"],  # [input_group, subgroup] for stage 1\n",
    "        [\"dihedral\", \"dihedral\"],  # For stage 2\n",
    "        [\"dihedral\", \"dihedral\"]   # For stage 3\n",
    "    ],\n",
    "    subsampling_factors=[2, 1, 1],  # Group reduction factors per stage\n",
    "    spatial_subsampling_factors=[2, 1, 1],  # Spatial downsampling factors\n",
    "    num_classes=10,    # STL-10 has 10 classes\n",
    "    antialiasing_kwargs={\n",
    "        \"iterations\": 100,  # Anti-aliasing optimization steps\n",
    "        \"smoothness_loss_weight\": 0.5  # Trade-off between equivariance and smoothness\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture Breakdown\n",
    "\n",
    "| Stage | Channels | Group Subsampling | Spatial Subsampling | Feature Map Size* |\n",
    "|-------|----------|-------------------|---------------------|-------------------|\n",
    "| 1     | 32       | D12 → D6 (2x)     | 64x64 → 32x32 (2x)  | 32x32             |\n",
    "| 2     | 64       | D6 → D6 (1x)      | 32x32 → 32x32 (1x)  | 32x32             |\n",
    "| 3     | 128      | D6 → D6 (1x)      | 32x32 → 32x32 (1x)  | 32x32             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with g-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Train Loss: 1.9300 | Acc: 28.80%\n",
      "Test Acc: 37.74%\n",
      "LR: 3.00e-04\n",
      "\n",
      "Epoch 2/100\n",
      "Train Loss: 1.5408 | Acc: 43.44%\n",
      "Test Acc: 46.25%\n",
      "LR: 3.00e-04\n",
      "\n",
      "Epoch 3/100\n",
      "Train Loss: 1.3102 | Acc: 53.22%\n",
      "Test Acc: 47.30%\n",
      "LR: 3.00e-04\n",
      "\n",
      "Epoch 4/100\n",
      "Train Loss: 1.0909 | Acc: 63.12%\n",
      "Test Acc: 49.92%\n",
      "LR: 3.00e-04\n",
      "\n",
      "Epoch 5/100\n",
      "Train Loss: 0.9104 | Acc: 69.92%\n",
      "Test Acc: 48.92%\n",
      "LR: 3.00e-04\n",
      "\n",
      "Epoch 6/100\n",
      "Train Loss: 0.6951 | Acc: 78.86%\n",
      "Test Acc: 50.10%\n",
      "LR: 2.99e-04\n",
      "\n",
      "Epoch 7/100\n",
      "Train Loss: 0.4910 | Acc: 86.58%\n",
      "Test Acc: 49.80%\n",
      "LR: 2.99e-04\n",
      "\n",
      "Epoch 8/100\n",
      "Train Loss: 0.3581 | Acc: 90.90%\n",
      "Test Acc: 51.36%\n",
      "LR: 2.99e-04\n",
      "\n",
      "Epoch 9/100\n",
      "Train Loss: 0.2138 | Acc: 95.88%\n",
      "Test Acc: 48.74%\n",
      "LR: 2.99e-04\n",
      "\n",
      "Epoch 10/100\n",
      "Train Loss: 0.1264 | Acc: 98.40%\n",
      "Test Acc: 50.11%\n",
      "LR: 2.98e-04\n",
      "\n",
      "Epoch 11/100\n",
      "Train Loss: 0.0631 | Acc: 99.76%\n",
      "Test Acc: 50.50%\n",
      "LR: 2.98e-04\n",
      "\n",
      "Epoch 12/100\n",
      "Train Loss: 0.0306 | Acc: 99.98%\n",
      "Test Acc: 50.60%\n",
      "LR: 2.97e-04\n",
      "\n",
      "Epoch 13/100\n",
      "Train Loss: 0.0198 | Acc: 99.98%\n",
      "Test Acc: 50.30%\n",
      "LR: 2.97e-04\n",
      "\n",
      "Epoch 14/100\n",
      "Train Loss: 0.0142 | Acc: 100.00%\n",
      "Test Acc: 50.79%\n",
      "LR: 2.96e-04\n",
      "\n",
      "Epoch 15/100\n",
      "Train Loss: 0.0105 | Acc: 100.00%\n",
      "Test Acc: 50.64%\n",
      "LR: 2.96e-04\n",
      "\n",
      "Epoch 16/100\n",
      "Train Loss: 0.0084 | Acc: 100.00%\n",
      "Test Acc: 50.76%\n",
      "LR: 2.95e-04\n",
      "\n",
      "Epoch 17/100\n",
      "Train Loss: 0.0069 | Acc: 100.00%\n",
      "Test Acc: 50.58%\n",
      "LR: 2.95e-04\n",
      "\n",
      "Epoch 18/100\n",
      "Train Loss: 0.0056 | Acc: 100.00%\n",
      "Test Acc: 50.48%\n",
      "LR: 2.94e-04\n",
      "\n",
      "Epoch 19/100\n",
      "Train Loss: 0.0049 | Acc: 100.00%\n",
      "Test Acc: 50.66%\n",
      "LR: 2.93e-04\n",
      "\n",
      "Epoch 20/100\n",
      "Train Loss: 0.0042 | Acc: 100.00%\n",
      "Test Acc: 50.51%\n",
      "LR: 2.93e-04\n",
      "\n",
      "Epoch 21/100\n",
      "Train Loss: 0.0037 | Acc: 100.00%\n",
      "Test Acc: 50.41%\n",
      "LR: 2.92e-04\n",
      "\n",
      "Epoch 22/100\n",
      "Train Loss: 0.0032 | Acc: 100.00%\n",
      "Test Acc: 50.62%\n",
      "LR: 2.91e-04\n",
      "\n",
      "Epoch 23/100\n",
      "Train Loss: 0.0028 | Acc: 100.00%\n",
      "Test Acc: 50.44%\n",
      "LR: 2.90e-04\n",
      "\n",
      "Epoch 24/100\n",
      "Train Loss: 0.0025 | Acc: 100.00%\n",
      "Test Acc: 50.27%\n",
      "LR: 2.89e-04\n",
      "\n",
      "Epoch 25/100\n",
      "Train Loss: 0.0022 | Acc: 100.00%\n",
      "Test Acc: 50.52%\n",
      "LR: 2.89e-04\n",
      "\n",
      "Epoch 26/100\n",
      "Train Loss: 0.0020 | Acc: 100.00%\n",
      "Test Acc: 50.62%\n",
      "LR: 2.88e-04\n",
      "\n",
      "Epoch 27/100\n",
      "Train Loss: 0.0019 | Acc: 100.00%\n",
      "Test Acc: 50.46%\n",
      "LR: 2.87e-04\n",
      "\n",
      "Epoch 28/100\n",
      "Train Loss: 0.0016 | Acc: 100.00%\n",
      "Test Acc: 50.50%\n",
      "LR: 2.86e-04\n",
      "\n",
      "Epoch 29/100\n",
      "Train Loss: 0.0015 | Acc: 100.00%\n",
      "Test Acc: 50.55%\n",
      "LR: 2.85e-04\n",
      "\n",
      "Epoch 30/100\n",
      "Train Loss: 0.0014 | Acc: 100.00%\n",
      "Test Acc: 50.42%\n",
      "LR: 2.84e-04\n",
      "\n",
      "Epoch 31/100\n",
      "Train Loss: 0.0013 | Acc: 100.00%\n",
      "Test Acc: 50.48%\n",
      "LR: 2.83e-04\n",
      "\n",
      "Epoch 32/100\n",
      "Train Loss: 0.0012 | Acc: 100.00%\n",
      "Test Acc: 50.24%\n",
      "LR: 2.81e-04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Configure data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(96),  # STL-10 has 96x96 images\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(96),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.STL10(\n",
    "    root='./data', \n",
    "    split='train',\n",
    "    download=True, \n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.STL10(\n",
    "    root='./data',\n",
    "    split='test',\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "\n",
    "# ## Training Loop with Equivariance Monitoring\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Metrics\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "        \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = outputs.max(1)\n",
    "            test_correct += predicted.eq(targets).sum().item()\n",
    "            test_total += targets.size(0)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {total_loss/len(train_loader):.4f} | Acc: {100.*correct/total:.2f}%\")\n",
    "    print(f\"Test Acc: {100.*test_correct/test_total:.2f}%\")\n",
    "    print(f\"LR: {scheduler.get_last_lr()[0]:.2e}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groups",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
